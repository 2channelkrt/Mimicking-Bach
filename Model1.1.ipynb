{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import csvFile as csv\n",
    "import numpy as np\n",
    "\n",
    "#########################user configuration variables############################\n",
    "#defining basic file paths.\n",
    "\n",
    "basePath=os.getcwd()## default work path will be here.\n",
    "midiFileRelativePath=r'\\midicsv-1.1\\midi'#where training data is stored\n",
    "midicsvRelPath=r'\\midicsv-1.1'#midicsv location\n",
    "csvRelPath=r'\\midicsv-1.1\\csv'#where csv file will be stored\n",
    "#################################################################################\n",
    "#defining absolute path...\n",
    "midiFileAbsPath=basePath+midiFileRelativePath\n",
    "midicsvWorkingPath=basePath+midicsvRelPath\n",
    "csvAbsPath=basePath+csvRelPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv files already created\n",
      "96 csv files detected\n"
     ]
    }
   ],
   "source": [
    "files=sorted(os.listdir(midiFileAbsPath))#retreving training data\n",
    "\n",
    "#converting training data midi files for convenience.\n",
    "#This naming onvention will be used for rest of the process\n",
    "if(files[0]!='0.mid'):\n",
    "    print('filenames not converted. Converting...')\n",
    "    os.chdir(midiFileAbsPath)\n",
    "    i=0\n",
    "    for fileName in files:\n",
    "        os.rename(fileName,str(i)+'.mid')\n",
    "        i+=1\n",
    "    print(\"filenames converted\")\n",
    "\n",
    "files=sorted(os.listdir(midiFileAbsPath))\n",
    "\n",
    "#creating csv files from training data, using 'midicsv'\n",
    "checkFiles=sorted(os.listdir(csvAbsPath))\n",
    "if(checkFiles[0]!=\"0.csv\"):\n",
    "    for fileName in files:\n",
    "        newFileName=fileName[:-4]\n",
    "        cmd='midicsv ./midi/'+fileName+' ./csv/'+newFileName+'.csv'\n",
    "        os.system(cmd)\n",
    "        print('raw csv files created')\n",
    "else:\n",
    "     print(\"csv files already created\")\n",
    "\n",
    "fileList=sorted(os.listdir(csvAbsPath))\n",
    "print(\"%d csv files detected\"% len(fileList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all csv data, and retreving metatada.\n",
    "myFile=[]\n",
    "os.chdir(csvAbsPath)\n",
    "for files in fileList:\n",
    "    myFile.append(csv.csvFile(files))\n",
    "    myFile[len(myFile)-1].convert2InputFormat()\n",
    "    myFile[len(myFile)-1].getBasicTimeStep()\n",
    "    myFile[len(myFile)-1].createInputData1()\n",
    "    myFile[len(myFile)-1].createInputData1()\n",
    "    #myFile[len(myFile)-1].convert2OutputFormat(convertedAbsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60, 77], [60, 73], [60, 68], [60, 73], [60, 77], [60, 73], [60, 78], [60, 73], [60, 78], [60, 73], [60, 78], [60, 73], [60, 80], [60, 73], [60, 80], [60, 73], [60, 80], [60, 73], [60, 82], [60, 73], [60, 82], [60, 73], [60, 82], [60, 73], [60, 80], [60, 73], [60, 80], [60, 73], [60, 80], [60, 73], [60, 78], [60, 77], [60, 75], [60, 77], [60, 78], [60, 75], [60, 77], [60, 75], [60, 73], [60, 75], [60, 77], [60, 73], [60, 75], [60, 77], [60, 75], [60, 73], [60, 72], [60, 70], [240, 68], [120, 80], [240, 70], [120, 80], [240, 72], [120, 80], [240, 73], [120, 80], [240, 72], [120, 80], [240, 70], [120, 79], [240, 68], [240, 80], [60, 78], [60, 77], [60, 75], [60, 77], [60, 78], [60, 75], [60, 70], [60, 75], [60, 78], [60, 75], [60, 80], [60, 75], [60, 80], [60, 75], [60, 80], [60, 75], [60, 82], [60, 75], [60, 82], [60, 75], [60, 82], [60, 75], [60, 83], [60, 75], [60, 83], [60, 75], [60, 83], [60, 75], [60, 82], [60, 75], [60, 82], [60, 75], [60, 82], [60, 75], [60, 80], [60, 78], [60, 77], [60, 78], [60, 80], [60, 77], [60, 78], [60, 77], [60, 75], [60, 77], [60, 78], [60, 75], [60, 77], [60, 78], [60, 77], [60, 75], [60, 73], [60, 72], [240, 70], [120, 82], [240, 72], [120, 82], [240, 73], [120, 82], [240, 75], [120, 82], [240, 73], [120, 82], [240, 72], [120, 81], [240, 70], [240, 82], [120, 80], [120, 79], [120, 80], [120, 68], [240, 80], [120, 78], [120, 77], [60, 78], [60, 77], [60, 75], [60, 77], [60, 78], [60, 75], [60, 81], [60, 79], [60, 77], [60, 79], [60, 81], [60, 77], [60, 82], [60, 81], [60, 82], [60, 84], [60, 82], [60, 80], [60, 79], [60, 77], [60, 75], [60, 77], [60, 79], [60, 75], [120, 80], [120, 68], [240, 80], [120, 78], [120, 77], [120, 78], [120, 66], [240, 78], [120, 77], [120, 75], [60, 77], [60, 75], [60, 73], [60, 75], [60, 77], [60, 73], [60, 79], [60, 77], [60, 75], [60, 77], [60, 79], [60, 75], [60, 80], [60, 79], [60, 80], [60, 82], [60, 80], [60, 78], [60, 77], [60, 75], [60, 73], [60, 75], [60, 77], [60, 73], [240, 66], [120, 78], [240, 68], [120, 78], [240, 70], [120, 78], [240, 71], [120, 78], [240, 70], [120, 78], [240, 68], [120, 77], [240, 66], [240, 78], [60, 77], [60, 75], [60, 73], [60, 75], [60, 77], [60, 73], [60, 68], [60, 73], [60, 77], [60, 73], [60, 78], [60, 73], [60, 78], [60, 73], [60, 78], [60, 73], [60, 80], [60, 73], [60, 80], [60, 73], [60, 80], [60, 73], [60, 82], [60, 73], [60, 82], [60, 73], [60, 82], [60, 73], [60, 80], [60, 73], [60, 80], [60, 73], [60, 80], [60, 73], [60, 78], [60, 77], [60, 75], [60, 77], [60, 78], [60, 75], [60, 77], [60, 75], [60, 73], [60, 75], [60, 77], [60, 73], [60, 75], [60, 77], [60, 75], [60, 73], [60, 72], [60, 70], [60, 72], [120, 68], [120, 68], [60, 68], [60, 72], [120, 68], [120, 68], [60, 68], [60, 73], [120, 68], [120, 68], [60, 68], [60, 73], [120, 68], [120, 68], [60, 68], [60, 78], [120, 68], [120, 68], [60, 68], [60, 78], [120, 68], [120, 68], [60, 68], [60, 77], [120, 68], [120, 68], [60, 68], [60, 77], [120, 68], [120, 68], [60, 68], [60, 79], [120, 70], [120, 70], [60, 70], [60, 79], [120, 70], [120, 70], [60, 70], [60, 80], [120, 72], [120, 72], [60, 72], [60, 80], [120, 72], [120, 72], [60, 72], [60, 80], [120, 73], [120, 68], [120, 73], [120, 77], [120, 80], [60, 82], [60, 83], [60, 82], [60, 80], [60, 78], [60, 77], [60, 75], [60, 77], [60, 78], [60, 80], [60, 83], [60, 82], [60, 80], [60, 82], [120, 75], [120, 66], [120, 70], [120, 75], [120, 78], [60, 80], [60, 81], [60, 80], [60, 78], [60, 76], [60, 75], [60, 73], [60, 75], [60, 76], [60, 78], [60, 81], [60, 80], [60, 78], [60, 80], [120, 73], [120, 76], [120, 73], [120, 69], [120, 66], [120, 75], [120, 68], [120, 64], [120, 73], [120, 69], [120, 66], [60, 63], [60, 60], [120, 56], [120, 56], [60, 56], [60, 60], [120, 56], [120, 56], [60, 56], [60, 61], [120, 56], [120, 56], [60, 56], [60, 61], [120, 56], [120, 56], [60, 56], [60, 66], [120, 56], [120, 56], [60, 56], [60, 66], [120, 56], [120, 56], [60, 56], [60, 65], [120, 56], [120, 56], [60, 56], [60, 65], [120, 56], [120, 56], [60, 56], [60, 67], [120, 58], [120, 58], [60, 58], [60, 67], [120, 58], [120, 58], [420, 58], [60, 61], [60, 64], [60, 67], [60, 70], [60, 73], [60, 76], [60, 72], [60, 75], [60, 78], [60, 75], [60, 72], [420, 68], [60, 65], [60, 68], [60, 73], [60, 68], [60, 65], [540, 61], [120, 65], [120, 63]]\n"
     ]
    }
   ],
   "source": [
    "#let's test out if training data is imported correctly.\n",
    "#data should start with something like this...\n",
    "#[[60, 77], [60, 73], [60, 68], [60, 73], [60, 77], [60, 73], ...\n",
    "print(myFile[2].inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for integrating all seperate training data\n",
    "raw_data=[]\n",
    "for f in myFile:\n",
    "    raw_data.append(f.inputData)\n",
    "\n",
    "def createBeatLib(data):\n",
    "    _dict={}\n",
    "    for track in data:\n",
    "        for beat, _ in track:\n",
    "            if beat not in _dict:\n",
    "                _dict[beat]=1\n",
    "            else:\n",
    "                _dict[beat]+=1\n",
    "    return _dict\n",
    "def createNoteLib(data):\n",
    "    _dict={}\n",
    "    for track in data:\n",
    "        for _, note in track:\n",
    "            if note not in _dict:\n",
    "                _dict[note]=1\n",
    "            else:\n",
    "                _dict[note]+=1\n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{60: 20783, 68: 5, 30: 2607, 22: 454, 23: 462, 67: 8, 120: 8591, 720: 168, 780: 31, 240: 1982, 300: 344, 180: 733, 26: 65, 19: 255, 18: 80, 15: 263, 540: 97, 480: 662, 360: 702, 420: 98, 270: 12, 90: 74, 1080: 32, 600: 185, 1020: 7, 75: 11, 840: 69, 45: 151, 1260: 3, 660: 8, 165: 20, 34: 19, 41: 9, 124: 7, 596: 3, 27: 21, 191: 2, 38: 68, 2760: 2, 1200: 33, 900: 1, 1196: 1, 476: 1, 236: 2, 364: 1, 1800: 4, 2520: 3, 960: 77, 101: 4, 645: 2, 135: 13, 105: 1, 255: 1, 1560: 12, 735: 1, 37: 62, 8: 6, 11: 21, 12: 5, 52: 5, 1920: 10, 2040: 5, 3480: 4, 1440: 9, 150: 50, 118: 3, 302: 1, 390: 6, 24: 5, 25: 8, 58: 2, 71: 2, 109: 2, 20: 8, 21: 1, 40: 1170, 280: 1, 2340: 2, 225: 2, 330: 17, 210: 6, 1050: 1, 570: 3, 199: 1, 510: 2, 2160: 5, 3120: 1, 82: 7, 160: 22, 98: 1, 262: 1, 1500: 3, 33: 1, 49: 4, 619: 1, 2220: 1, 1320: 5, 232: 1, 750: 1, 1980: 1, 3000: 3, 17: 2, 9: 1, 127: 1, 94: 1, 142: 8, 5040: 1, 53: 2, 1680: 8, 12480: 1, 12000: 1, 187: 1, 1140: 1, 760: 1, 80: 377, 2880: 2, 4800: 1, 3840: 3, 3960: 1, 320: 16, 560: 10, 800: 4, 640: 8, 43: 1, 77: 1, 1040: 2, 1280: 1, 400: 4, 5: 1, 7: 1, 8160: 1, 1620: 1, 13560: 1, 4320: 1, 630: 1, 2640: 2, 8640: 1, 7680: 1}\n"
     ]
    }
   ],
   "source": [
    "#let's check raw beat data\n",
    "    #key: length of the beat\n",
    "    #value: occurance frequency\n",
    "print(createBeatLib(raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################user configuration variables############################\n",
    "#This model tries to cut out some 'exceptionally rare' notes for following reasons\n",
    "    #1. this note might be from chorus, not melody\n",
    "    #2. number of parameters become too big\n",
    "cuttingEdge=100 #beat with occurance frequency below this threshold will be transposed or omitted\n",
    "\n",
    "#transpose\n",
    "#if note is considered 'exceptionally rare', that note will be shifted to be\n",
    "#shorter or longer beat. Since 1 beat is in terms of milliseconds for this project, small shift tends to be unnoticable.\n",
    "#this helps to tolerate minor rounding error of original csv data converted from midi files.\n",
    "\n",
    "transposeHigh=5 # transpose upper threshold\n",
    "transposeLow=5 # transpose lower threshold\n",
    "#################################################################################\n",
    "#This transposes all data in terms of note height. keys below 36 was never used.\n",
    "noteTransPose=36\n",
    "\n",
    "total_data=[]\n",
    "#actually integrating all seperate training data\n",
    "beatLib=createBeatLib(raw_data)\n",
    "\n",
    "for track in raw_data:\n",
    "    newTrack=[]\n",
    "    for beat, note in track:\n",
    "        if(beatLib[beat]>cuttingEdge):\n",
    "            newTrack.append([beat,note-noteTransPose])\n",
    "        else:\n",
    "            for i in range(-transposeLow,transposeHigh):\n",
    "                if((beat+i) in beatLib and beatLib[(beat+i)]>cuttingEdge):\n",
    "                    newTrack.append([(beat+i),note-noteTransPose])\n",
    "                    break\n",
    "    total_data.append(newTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355\n"
     ]
    }
   ],
   "source": [
    "#########################user configuration variables############################\n",
    "#length of the training & creating melody. In terms of 'note events'\n",
    "seqLength=100\n",
    "#################################################################################\n",
    "new_total_data=[]\n",
    "\n",
    "#leftover data is not used\n",
    "for track in total_data:\n",
    "    _size=len(track)//seqLength\n",
    "    for i in range(_size):\n",
    "        new_total_data.append(track[i*seqLength:(i+1)*seqLength+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(new_total_data))\n",
    "\n",
    "data_limiter=350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating shifted index for the output part of the model.\n",
    "\n",
    "total_data_x=[]\n",
    "total_data_y=[]\n",
    "def shift(x):\n",
    "    out=[]\n",
    "    for i in range(len(x)):\n",
    "        if(i==0):\n",
    "            continue\n",
    "        out.append(x[i])\n",
    "    return out\n",
    "\n",
    "for i in new_total_data:\n",
    "    total_data_y.append(shift(i))\n",
    "\n",
    "for i in new_total_data:\n",
    "    total_data_x.append(i[:-1])\n",
    "\n",
    "train_x=total_data_x[:350]\n",
    "train_y=total_data_y[:350]\n",
    "\n",
    "test_x=total_data_x[350:]\n",
    "test_y=total_data_y[350:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41199\n",
      "40297\n",
      "-902\n",
      "17\n",
      "96\n",
      "442\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#comparison between optimized & raw data\n",
    "newBeatLib=createBeatLib(total_data)\n",
    "\n",
    "print(sum(beatLib.values()))\n",
    "print(sum(newBeatLib.values()))\n",
    "print(sum(newBeatLib.values())-sum(beatLib.values()))\n",
    "print(len(newBeatLib))\n",
    "print(len(total_data))\n",
    "print(len(total_data[0]))\n",
    "print(len(total_data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 19, 22, 23, 30, 40, 45, 60, 80, 120, 180, 240, 300, 360, 480, 600, 720]\n"
     ]
    }
   ],
   "source": [
    "#optimized beat list.\n",
    "beatList=[]\n",
    "\n",
    "for key, val in newBeatLib.items():\n",
    "    beatList.append(key)\n",
    "\n",
    "beatList.sort()\n",
    "print(beatList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating one-hot vectors based on the optimized data.\n",
    "numClasses=(88-noteTransPose)*len(newBeatLib)\n",
    "\n",
    "def one_hotify(element, _beatLib):\n",
    "    beat, note=element\n",
    "    a=np.zeros(numClasses)\n",
    "    a[note*(_beatLib.index(beat)+1)]=1\n",
    "    return a\n",
    "\n",
    "new_train_x=[]\n",
    "new_train_y=[]\n",
    "new_test_x=[]\n",
    "new_test_y=[]\n",
    "\n",
    "for i in train_x:\n",
    "    i_s=[]\n",
    "    for j in i:\n",
    "        i_s.append(one_hotify(j, beatList))\n",
    "    new_train_x.append(i_s)\n",
    "for i in train_y:\n",
    "    i_s=[]\n",
    "    for j in i:\n",
    "        i_s.append(one_hotify(j, beatList))\n",
    "    new_train_y.append(i_s)\n",
    "for i in test_x:\n",
    "    i_s=[]\n",
    "    for j in i:\n",
    "        i_s.append(one_hotify(j, beatList))\n",
    "    new_test_x.append(i_s)\n",
    "for i in test_y:\n",
    "    i_s=[]\n",
    "    for j in i:\n",
    "        i_s.append(one_hotify(j, beatList))\n",
    "    new_test_y.append(i_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 100, 884)\n"
     ]
    }
   ],
   "source": [
    "#final shape of the input\n",
    "print(np.asarray(new_train_x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below is standard tensorflow stuff.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=35\n",
    "def getBatch(x,y):\n",
    "    start=(getBatch.index*batch_size)%350\n",
    "    getBatch.index+=1\n",
    "    end=start+batch_size\n",
    "    \n",
    "    seq=np.arange(start,end)\n",
    "    np.random.shuffle(seq)\n",
    "    train=seq[:30]\n",
    "    val=seq[30:]\n",
    "    \n",
    "    tx, ty, vx, vy = [], [], [], []\n",
    "    for i in train:\n",
    "        tx.append(x[i])\n",
    "        ty.append(y[i])\n",
    "    for i in val:\n",
    "        vx.append(x[i])\n",
    "        vy.append(y[i])\n",
    "    return tx, ty, vx, vy\n",
    "getBatch.index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden=256\n",
    "num_classes=len(new_train_x[0][0])\n",
    "learning_rate=0.01\n",
    "LSTM_LAYER_SIZE=1\n",
    "FORGET_BIAS=1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X=tf.placeholder(tf.float32, [None,None,num_classes])\n",
    "Y=tf.placeholder(tf.float32, [None,None,num_classes])\n",
    "\n",
    "cells = [rnn.BasicLSTMCell(num_hidden, forget_bias=FORGET_BIAS) for _ in range(LSTM_LAYER_SIZE)]\n",
    "cells = rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "cbatch_size=tf.shape(X)[0]\n",
    "init_state=cells.zero_state(cbatch_size, dtype=tf.float32)\n",
    "\n",
    "output, last_state = tf.nn.dynamic_rnn(inputs=X, cell=cells, dtype=tf.float32, initial_state=init_state)\n",
    "\n",
    "logits=tf.contrib.layers.fully_connected(output, num_classes, activation_fn=tf.nn.relu)\n",
    "\n",
    "scores=tf.nn.softmax(logits)\n",
    "my_predictions=tf.one_hot(tf.argmax(scores, 2), num_classes)\n",
    "\n",
    "losses=tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y)\n",
    "tot_loss=tf.reduce_mean(losses)\n",
    "optimizer=tf.train.RMSPropOptimizer(learning_rate=learning_rate,decay=0.9).minimize(tot_loss)\n",
    "\n",
    "sess=tf.Session()\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1140, 1024) dtype=float32_ref>\n",
      "(1140, 1024)\n",
      "2\n",
      "1140\n",
      "1024\n",
      "1167360\n",
      "<tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
      "(1024,)\n",
      "1\n",
      "1024\n",
      "1024\n",
      "<tf.Variable 'fully_connected/weights:0' shape=(256, 884) dtype=float32_ref>\n",
      "(256, 884)\n",
      "2\n",
      "256\n",
      "884\n",
      "226304\n",
      "<tf.Variable 'fully_connected/biases:0' shape=(884,) dtype=float32_ref>\n",
      "(884,)\n",
      "1\n",
      "884\n",
      "884\n",
      "1395572\n"
     ]
    }
   ],
   "source": [
    "#checkign all parameters\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    print(variable)\n",
    "    shape = variable.get_shape()\n",
    "    print(shape)\n",
    "    print(len(shape))\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        print(dim)\n",
    "        variable_parameters *= dim.value\n",
    "    print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(midicsvWorkingPath)\n",
    "saverRelPath=r'\\save\\save'\n",
    "saveAbsPath=midicsvWorkingPath+saverRelPath\n",
    "saver=tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "train_guess=[]\n",
    "    \n",
    "getBatch.index=0\n",
    "\n",
    "def train(training_step, guesses, save_step=50, view_step=3,):\n",
    "    for step in range(training_step):\n",
    "        #fetchData={'fianl_state': last_state, 'prediction': pred}\n",
    "        tx, ty, vx, vy = getBatch(new_train_x, new_train_y)\n",
    "        feedData={X: tx, Y: ty}\n",
    "\n",
    "        sess.run(optimizer, feed_dict=feedData)\n",
    "        if(step%save_step==0):\n",
    "            guesses.append(my_predictions.eval(feed_dict={X: tx+ty}, session=sess))\n",
    "            saver.save(sess, saveAbsPath, global_step=step)\n",
    "        if(step%view_step==0):\n",
    "            tr_loss=sess.run(tot_loss, feed_dict={X:tx, Y:ty})\n",
    "            val_loss=sess.run(tot_loss, feed_dict={X:vx, Y:vy})\n",
    "            print(\"step %d, training_loss: %f validation_loss: %f\"%(step, tr_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training_loss: 6.784488 validation_loss: 6.785092\n",
      "step 10, training_loss: 6.783749 validation_loss: 6.783457\n",
      "step 20, training_loss: 6.781642 validation_loss: 6.780204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-230685433de9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_guess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-b9f181bb00fd>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(training_step, guesses, save_step, view_step)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mfeedData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mty\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeedData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0msave_step\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mguesses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mty\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(1000, train_guess, save_step=100, view_step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(seed, length=100):\n",
    "    guesses=[]\n",
    "    fetchData= {'final_state': last_state,'prediction': my_predictions}\n",
    "    element=[60,65-noteTransPose+seed]\n",
    "    d=why(element,beatList)\n",
    "    init_input=np.reshape(d,(1,1,884))\n",
    "    feedData={X: init_input}\n",
    "    \n",
    "    eval_out=sess.run(fetchData, feedData)\n",
    "    guesses=[]\n",
    "    guesses.append(eval_out['prediction'])\n",
    "    \n",
    "    \n",
    "    next_state=eval_out['final_state']\n",
    "    for step in range(1,length):\n",
    "        feedData={X: guesses[-1], init_state:next_state}\n",
    "        eval_out=sess.run(fetchData,feedData)\n",
    "        guesses.append(eval_out['prediction'])\n",
    "        \n",
    "        next_state=eval_out['final_state']\n",
    "    return guesses\n",
    "create_guess=[]\n",
    "for i in range(-10,10):\n",
    "    create_guess.append(create(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEATLIB=sorted(newBeatLib.items(), key=lambda kv: kv[1])\n",
    "list.reverse(BEATLIB)\n",
    "\n",
    "def rev_why(element, _beatLib, orderLIB=BEATLIB):\n",
    "    index=np.argmax(element)\n",
    "    for beat, _ in orderLIB:\n",
    "        if(index%(_beatLib.index(beat)+1)==0):\n",
    "            tempNote=index//(_beatLib.index(beat)+1)\n",
    "            if(0<=tempNote and tempNote<88-noteTransPose):\n",
    "                return [beat, tempNote+noteTransPose]\n",
    "    raise ValueError('note not identified')\n",
    "\n",
    "CREATED=[]\n",
    "for track in create_guess:\n",
    "    TRACK=[]\n",
    "    for element in track:\n",
    "        TRACK.append(rev_why(element, beatList))\n",
    "    CREATED.append(TRACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60, 61], [60, 63], [60, 64], [60, 66], [60, 68], [60, 70], [30, 43], [23, 53], [60, 73], [30, 75], [30, 73], [30, 75], [30, 73], [30, 75], [30, 73], [30, 71], [30, 73], [60, 75], [60, 70], [60, 71], [60, 75], [60, 76], [60, 70], [60, 71], [60, 76], [60, 78], [60, 71], [60, 80], [60, 78], [60, 76], [60, 75], [60, 73], [60, 71], [60, 69], [60, 76], [60, 75], [60, 81], [60, 71], [60, 73], [60, 75], [60, 76], [60, 78], [60, 80], [30, 81], [120, 58], [60, 80], [60, 78], [60, 76], [60, 80], [60, 73], [60, 80], [60, 73], [60, 76], [60, 69], [60, 73], [60, 76], [60, 78], [60, 76], [60, 75], [60, 76], [60, 73], [60, 71], [60, 73], [60, 76], [60, 75], [60, 73], [60, 71], [60, 69], [60, 68], [120, 78], [60, 84], [60, 78], [60, 80], [120, 83], [240, 73], [360, 76], [120, 75], [240, 78], [240, 77], [240, 75], [120, 80], [120, 78], [120, 77], [120, 75], [120, 77], [120, 78], [120, 80], [120, 82], [120, 83], [120, 82], [120, 80], [120, 78], [120, 80], [60, 73], [60, 71], [60, 70], [240, 85], [240, 77], [240, 85], [240, 77]]\n"
     ]
    }
   ],
   "source": [
    "print(CREATED[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "my_track=[]\n",
    "\n",
    "def createOutputData1(track): #support only 1 dimension\n",
    "    output=[]\n",
    "    \n",
    "    pBeat=0\n",
    "    \n",
    "    for beat, note in track:\n",
    "        output.append([pBeat,[note]])\n",
    "        pBeat+=beat\n",
    "    return output\n",
    "\n",
    "for track in CREATED:\n",
    "    my_track.append(createOutputData1(track))\n",
    "\n",
    "print(len(my_track[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "outRelPath=r'\\midicsv-1.1\\out'\n",
    "outAbsPath=basePath+outRelPath\n",
    "\n",
    "def writeTrack(f, hardtrackNum, softTrackNum, source):##int values are sent as str\n",
    "    fresh=True\n",
    "    last_pitch=''\n",
    "    last_timeStamp=''\n",
    "    f.write(hardtrackNum+', 0, Start_track\\n')\n",
    "    f.write(hardtrackNum+', 0, Title_t, \"Track '+str(int(hardtrackNum)-1)+'\"\\n')\n",
    "    f.write(hardtrackNum+', 0, Program_c, '+str(int(hardtrackNum)-2)+', 6\\n') # 6 specifies instrument type?\n",
    "    for [key, val] in source:\n",
    "        if(len(val)>int(softTrackNum)):##only if val has current track key to play\n",
    "            if(fresh==False):\n",
    "                f.write(hardtrackNum+', '+str(int(key)-1)+', Note_off_c, '+str(int(hardtrackNum)-2)+', '+last_pitch+', 0\\n')\n",
    "            else:\n",
    "                fresh=False\n",
    "            last_pitch=str(val[int(softTrackNum)])\n",
    "            f.write(hardtrackNum+', '+str(key)+', Note_on_c, '+str(int(hardtrackNum)-2)+', '+str(val[int(softTrackNum)])+', 88\\n')\n",
    "            last_timeStamp=str(key)\n",
    "    f.write(hardtrackNum+', '+str(int(last_timeStamp)+40)+', Note_off_c, '+str(int(hardtrackNum)-2)+', '+last_pitch+', 0\\n')\n",
    "    f.write(hardtrackNum+', '+str(int(last_timeStamp)+40)+', End_track\\n')\n",
    "\n",
    "def writeCSV(track,fileName):\n",
    "    PathHeader=r'\\\\'\n",
    "    filePath=outAbsPath+PathHeader+fileName\n",
    "    f=open(filePath,\"w\")\n",
    "    maxTrackNum=1\n",
    "    f.write('0, 0, Header, 1, '+'2 '+', '+'240'+'\\n')\n",
    "    f.write('1, 0, Start_track\\n')\n",
    "    f.write('1, 0, Time_signature, 4, 2, 24, 8\\n')\n",
    "    f.write('1, 0, Tempo, '+'714285'+'\\n')#random number\n",
    "    f.write('1, 0, SMPTE_offset, 64, 0, 0, 0, 100\\n')\n",
    "    f.write('1, 0, End_track\\n')\n",
    "    \n",
    "    curHardTrackNum=2\n",
    "    ##write right hand\n",
    "    for i in range(0,1):\n",
    "        writeTrack(f,str(curHardTrackNum),str(i),track)\n",
    "        curHardTrackNum+=1\n",
    "\n",
    "    f.write('0, 0, End_of_file')\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(my_track)):\n",
    "    writeCSV(my_track[i], \"created_\"+str(i)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(midicsvWorkingPath)\n",
    "for i in range(len(my_track)):\n",
    "    fileName=\"created_\"+str(i)+\".csv\"\n",
    "    newFileName=\"created_\"+str(i)\n",
    "    cmd='csvmidi ./out/'+fileName+' ./out/'+newFileName+'.mid'\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
